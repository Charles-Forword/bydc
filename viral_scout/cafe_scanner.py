"""
ë„¤ì´ë²„ ì¹´í˜ í¬ë¡¤ëŸ¬
í†µí•©ê²€ìƒ‰ ì¹´í˜ íƒ­ì—ì„œ ê²Œì‹œê¸€ + ëŒ“ê¸€ ìˆ˜ì§‘
"""

import time
import hashlib
from playwright.sync_api import sync_playwright
from config import SEARCH_KEYWORDS, CAFE_MAX_POSTS

def generate_post_hash(author, title, content):
    """ì¤‘ë³µ ì œê±°ìš© í•´ì‹œ ìƒì„±"""
    unique_str = f"{author}{title}{content[:100]}"
    return hashlib.md5(unique_str.encode()).hexdigest()



def improve_cafe_name_extraction(page, initial_cafe_name):
    """
    ì¹´í˜ëª… ì¶”ì¶œ ê°œì„  (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
    
    Args:
        page: Playwright page ê°ì²´
        initial_cafe_name: ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ê°€ì ¸ì˜¨ ì´ˆê¸° ì¹´í˜ëª…
    
    Returns:
        str: ê°œì„ ëœ ì¹´í˜ëª…
    """
    # ì´ˆê¸° ì¹´í˜ëª…ì´ ìˆê³  ìœ íš¨í•˜ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if initial_cafe_name and initial_cafe_name.strip() and initial_cafe_name != "(ì—†ìŒ)":
        return initial_cafe_name
    
    # ìƒì„¸ í˜ì´ì§€ì—ì„œ ë‹¤ì‹œ ì¶”ì¶œ ì‹œë„
    try:
        iframe = page.frame_locator("iframe#cafe_main")
        
        cafe_name_selectors = [
            'h1.tit',  # ì¹´í˜ íƒ€ì´í‹€
            '.cafe_name',
            'a.cafe_name',
            '.gnb_cafe_title a',
            'h1.title_text'
        ]
        
        for selector in cafe_name_selectors:
            try:
                elem = iframe.locator(selector).first
                if elem.count() > 0:
                    cafe_name = elem.inner_text().strip()
                    if cafe_name:
                        # "ì¹´í˜ëª… - ë¶€ì œ" í˜•íƒœë©´ ì²« ë¶€ë¶„ë§Œ
                        cafe_name = cafe_name.split('-')[0].split('|')[0].strip()
                        return cafe_name
            except:
                continue
        
        # ë©”íƒ€ íƒœê·¸ì—ì„œ ì¶”ì¶œ ì‹œë„
        try:
            meta_cafe = page.locator('meta[property="og:site_name"]').first
            if meta_cafe.count() > 0:
                cafe_name = meta_cafe.get_attribute('content')
                if cafe_name:
                    return cafe_name
        except:
            pass
    
    except Exception as e:
        pass
    
    # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
    return initial_cafe_name if initial_cafe_name else "(ì¹´í˜ëª… ë¯¸í™•ì¸)"


def search_cafe_posts(keyword, max_posts=20):
    """
    ë„¤ì´ë²„ í†µí•©ê²€ìƒ‰ ì¹´í˜ íƒ­ì—ì„œ ê²Œì‹œê¸€ ìˆ˜ì§‘
    
    Args:
        keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
        max_posts: ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜
    
    Returns:
        list: ê²Œì‹œê¸€ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    results = []
    
    with sync_playwright() as p:
        # ë¸Œë¼ìš°ì € ì‹¤í–‰ (headless mode)
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        
        try:
            # 1. ë„¤ì´ë²„ í†µí•©ê²€ìƒ‰
            print(f"   ğŸ” ì¹´í˜ ê²€ìƒ‰: '{keyword}'")
            search_url = f"https://search.naver.com/search.naver?query={keyword}"
            page.goto(search_url, wait_until="networkidle")
            
            # 2. ì¹´í˜ íƒ­ í´ë¦­
            try:
                cafe_tab = page.locator("a.tab:has-text('ì¹´í˜')").first
                if cafe_tab.count() > 0:
                    cafe_tab.click()
                    page.wait_for_load_state("networkidle")
                else:
                    print(f"   âš ï¸ ì¹´í˜ íƒ­ ì—†ìŒ")
                    return results
            except Exception as e:
                print(f"   âš ï¸ ì¹´í˜ íƒ­ í´ë¦­ ì‹¤íŒ¨: {e}")
                return results
            
            
            # 3. ê²Œì‹œê¸€ ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ (ê´‘ê³  ì œì™¸, ì‹¤ì œ ì¹´í˜ ê²Œì‹œê¸€ë§Œ)
            # title_area í´ë˜ìŠ¤ë¥¼ ê°€ì§„ a íƒœê·¸ = ì‹¤ì œ ì œëª© ë§í¬
            title_links = page.locator("a[href*='cafe.naver.com'][class*='title']").all()
            
            print(f"   âœ… ì‹¤ì œ ì¹´í˜ ê²Œì‹œê¸€: {len(title_links)}ê°œ ë°œê²¬")
            print(f"   ğŸ“‹ ìˆ˜ì§‘ ì‹œì‘: {min(len(title_links), max_posts)}ê°œ")
            
            for idx, link_elem in enumerate(title_links[:max_posts]):
                try:
                    # ì œëª© & ë§í¬ (ì§ì ‘ ì¶”ì¶œ)
                    title = link_elem.inner_text().strip()
                    link = link_elem.get_attribute("href") or ""
                    
                    if not title or not link:
                        continue
                    
                    # ë¶€ëª¨ ìš”ì†Œ ì°¾ê¸°
                    parent = link_elem.locator('xpath=ancestor::li | ancestor::div[contains(@class,"api")]').first
                    
                    # ì¹´í˜ëª… ì°¾ê¸° (ì¹´í˜ ë§í¬ì—ì„œ)
                    cafe_link = parent.locator("a[href*='cafe.naver.com']:not([class*='title'])").first
                    cafe_name = ""
                    if cafe_link.count() > 0:
                        cafe_name_text = cafe_link.inner_text().strip()
                        # "ê°•ì‚¬ëª¨-ë°˜ë ¤ê²¬..." í˜•íƒœë©´ ì²« ë¶€ë¶„ë§Œ
                        cafe_name = cafe_name_text.split('-')[0].split('|')[0].strip()
                    
                    # ì‘ì„±ì
                    author = "ì¹´í˜íšŒì›"
                    
                    # ë‚ ì§œ ì°¾ê¸°
                    date_elem = parent.locator(".sub_time, span:has-text('.')").first
                    post_date = date_elem.inner_text().strip() if date_elem.count() > 0 else ""
                    
                    # ë¯¸ë¦¬ë³´ê¸° í…ìŠ¤íŠ¸
                    desc_elem = parent.locator(".dsc_area, .dsc_txt").first
                    description = desc_elem.inner_text().strip() if desc_elem.count() > 0 else ""
                    
                    print(f"   ğŸ“„ [{idx+1}] {title[:40]}... ({cafe_name})")
                    
                    # 4. ê²Œì‹œê¸€ ìƒì„¸ í˜ì´ì§€ ì ‘ì† (ìƒˆ íƒ­)
                    post_data = scrape_cafe_post_detail(p, link, title, author, cafe_name, post_date, description)
                    
                    if post_data:
                        results.append(post_data)
                    
                    time.sleep(1)  # ë¶€í•˜ ë°©ì§€
                    
                except Exception as e:
                    print(f"   âš ï¸ ê²Œì‹œê¸€ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue
            
        finally:
            browser.close()
    
    return results


def scrape_cafe_post_detail(playwright_instance, url, title, author, cafe_name, post_date, description):
    """
    ì¹´í˜ ê²Œì‹œê¸€ ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§
    
    Returns:
        dict: ê²Œì‹œê¸€ ë°ì´í„° (ë³¸ë¬¸, ëŒ“ê¸€ í¬í•¨)
    """
    browser = playwright_instance.chromium.launch(headless=True)
    page = browser.new_page()
    
    try:
        page.goto(url, wait_until="networkidle", timeout=15000)
        time.sleep(2)  # ë™ì  ë¡œë”© ëŒ€ê¸°
        
        # iframe í™•ì¸ (ì¹´í˜ëŠ” ë³´í†µ iframe ì‚¬ìš©)
        iframe = page.frame_locator("iframe#cafe_main")
        
        # ì¹´í˜ëª… ê°œì„  (ìƒì„¸ í˜ì´ì§€ì—ì„œ ì¬í™•ì¸)
        improved_cafe_name = improve_cafe_name_extraction(page, cafe_name)
        

        
        # ë³¸ë¬¸ ì¶”ì¶œ
        content = ""
        try:
            # ë³¸ë¬¸ ì„ íƒì (ì¹´í˜ë§ˆë‹¤ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
            content_selectors = [
                ".ContentRenderer",
                ".se-main-container",
                "#postContent",
                ".post-content"
            ]
            
            for selector in content_selectors:
                content_elem = iframe.locator(selector).first
                if content_elem.count() > 0:
                    content = content_elem.inner_text().strip()
                    break
            
            if not content:
                content = description  # í´ë°±: ë¯¸ë¦¬ë³´ê¸° ì‚¬ìš©
        
        except Exception as e:
            print(f"      âš ï¸ ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            content = description
        
        # ëŒ“ê¸€ ìˆ˜ì§‘
        comments = []
        try:
            comment_items = iframe.locator(".CommentItem").all()
            
            for comment_elem in comment_items[:20]:  # ìµœëŒ€ 20ê°œ
                try:
                    comment_author = comment_elem.locator(".comment_nickname").inner_text().strip()
                    comment_text = comment_elem.locator(".comment_text_view").inner_text().strip()
                    
                    comments.append({
                        "author": comment_author,
                        "content": comment_text
                    })
                except:
                    continue
        
        except Exception as e:
            print(f"      âš ï¸ ëŒ“ê¸€ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        # í•´ì‹œ ìƒì„±
        post_hash = generate_post_hash(author, title, content)
        
        return {
            "source": "ì¹´í˜",
            "cafe_name": improved_cafe_name,
            "title": title,
            "link": url,
            "author": author,
            "date": post_date,
            "content": content[:2000],  # 2000ì ì œí•œ
            "description": description,

            "comments": comments,
            "comment_count": len(comments),  # ëŒ“ê¸€ ìˆ˜ ì¶”ê°€
            "hash": post_hash
        }
    
    except Exception as e:
        print(f"      âš ï¸ ìƒì„¸ í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None
    
    finally:
        browser.close()


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    results = search_cafe_posts("ë³´ì–‘ëŒ€ì²©", max_posts=5)
    print(f"\nâœ… ìˆ˜ì§‘ ì™„ë£Œ: {len(results)}ê±´")
    
    for r in results:
        print(f"\nì œëª©: {r['title']}")
        print(f"ì¹´í˜: {r['cafe_name']}")
        print(f"ë³¸ë¬¸: {r['content'][:100]}...")
        print(f"ëŒ“ê¸€: {len(r['comments'])}ê°œ")
