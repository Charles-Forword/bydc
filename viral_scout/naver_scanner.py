import urllib.request
import urllib.parse
import json
import time
import ssl
import datetime
import os
import gspread
from oauth2client.service_account import ServiceAccountCredentials

# macOS SSL ì¸ì¦ì„œ ì˜¤ë¥˜ í•´ê²°ì„ ìœ„í•œ íŒ¨ì¹˜
ssl._create_default_https_context = ssl._create_unverified_context

from config import (
    NAVER_CLIENT_ID, NAVER_CLIENT_SECRET, 
    SEARCH_KEYWORDS, DISPLAY_COUNT, SORT_MODE,
    GOOGLE_SHEET_URL, SERVICE_ACCOUNT_FILE,
    TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID,
    EXCLUDE_KEYWORDS, REQUIRED_KEYWORDS, USE_AI_FILTER, OPENAI_API_KEY,
    ENABLE_CONTENT_SCRAPING, ENABLE_AI_ANALYSIS, ANALYZE_ALL,
    AI_PROVIDER, GEMINI_API_KEY
)

def scrape_blog_content(url):
    """ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë³¸ë¬¸ í¬ë¡¤ë§ (ì¬ì‹œë„ í¬í•¨)"""
    if not ENABLE_CONTENT_SCRAPING:
        return ""
    
    max_retries = 2
    for attempt in range(max_retries):
        try:
            from bs4 import BeautifulSoup
            import requests
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            content = soup.select_one('.se-main-container')
            if content:
                text = content.get_text(strip=True, separator=' ')[:2000]
                if len(text) > 100:
                    return text
            
            content = soup.select_one('#postViewArea')
            if content:
                text = content.get_text(strip=True, separator=' ')[:2000]
                if len(text) > 100:
                    return text
            
            paragraphs = soup.find_all(['p', 'div'], class_=lambda x: x and 'se-text' in x)
            if paragraphs:
                text = ' '.join([p.get_text(strip=True) for p in paragraphs])[:2000]
                if len(text) > 100:
                    return text
            
            if attempt < max_retries - 1:
                time.sleep(1)
                continue
            return "(ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨)"
            
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(1)
                continue
            print(f"      âš ï¸ í¬ë¡¤ë§ ì‹¤íŒ¨: {str(e)[:50]}")
            return "(ë³¸ë¬¸ ì—†ìŒ)"
    
    return "(ë³¸ë¬¸ ì—†ìŒ)"


def is_blacklisted(title):
    """ì œì™¸ í‚¤ì›Œë“œê°€ ì œëª©ì— ìˆëŠ”ì§€ í™•ì¸"""
    for keyword in EXCLUDE_KEYWORDS:
        if keyword in title:
            return True
    return False

def has_required_keyword(title):
    """í•„ìˆ˜ í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ ì œëª©ì— ìˆëŠ”ì§€ í™•ì¸"""
    for keyword in REQUIRED_KEYWORDS:
        if keyword in title:
            return True
    return False

def check_relevance_with_ai(title, description):
    """AIë¥¼ ì‚¬ìš©í•´ ë°˜ë ¤ë™ë¬¼ ì‚¬ë£Œ ê´€ë ¨ ê¸€ì¸ì§€ íŒë‹¨"""
    if not USE_AI_FILTER or not OPENAI_API_KEY:
        return True
    
    try:
        import requests
        
        prompt = f"""ë‹¤ìŒ ë¸”ë¡œê·¸ ê¸€ì´ "ë°˜ë ¤ë™ë¬¼(ê°•ì•„ì§€/ê³ ì–‘ì´) ì‚¬ë£Œ, ê°„ì‹, ì˜ì–‘ì œ" ê´€ë ¨ ë‚´ìš©ì¸ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.
ì‚¬ëŒì´ ë¨¹ëŠ” ìŒì‹, í•œì‹ ë ˆì‹œí”¼, ë§›ì§‘, ì¸í…Œë¦¬ì–´ ë“±ì€ ê´€ë ¨ ì—†ìŠµë‹ˆë‹¤.

ì œëª©: {title}
ìš”ì•½: {description}

ë‹µë³€ì€ "YES" ë˜ëŠ” "NO"ë¡œë§Œ í•´ì£¼ì„¸ìš”."""

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {OPENAI_API_KEY}"
        }
        
        data = {
            "model": "gpt-4o-mini",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.1,
            "max_tokens": 10
        }
        
        response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers=headers,
            json=data,
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            answer = result['choices'][0]['message']['content'].strip().upper()
            return "YES" in answer
        else:
            return True
            
    except Exception as e:
        return True


def analyze_content_with_ai(title, content):
    """AIë¡œ ë¸”ë¡œê·¸ ë³¸ë¬¸ ë¶„ì„í•˜ì—¬ êµ¬ì¡°í™”ëœ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
    if not ENABLE_AI_ANALYSIS:
        return {"ìš”ì•½": "", "ì£¼ìš”ë‚´ìš©": "", "ê²½ìŸì‚¬ì–¸ê¸‰": "", "ê°ì„±": "", "ì•¡ì…˜í¬ì¸íŠ¸": ""}
    
    if AI_PROVIDER == "gemini" and not GEMINI_API_KEY:
        return {"ìš”ì•½": "", "ì£¼ìš”ë‚´ìš©": "", "ê²½ìŸì‚¬ì–¸ê¸‰": "", "ê°ì„±": "", "ì•¡ì…˜í¬ì¸íŠ¸": ""}
    elif AI_PROVIDER == "openai" and not OPENAI_API_KEY:
        return {"ìš”ì•½": "", "ì£¼ìš”ë‚´ìš©": "", "ê²½ìŸì‚¬ì–¸ê¸‰": "", "ê°ì„±": "", "ì•¡ì…˜í¬ì¸íŠ¸": ""}
    
    if not ANALYZE_ALL and "ë³´ì–‘ëŒ€ì²©" not in title and "ë³´ì–‘ëŒ€ì²©" not in content:
        return {"ìš”ì•½": "", "ì£¼ìš”ë‚´ìš©": "", "ê²½ìŸì‚¬ì–¸ê¸‰": "", "ê°ì„±": "", "ì•¡ì…˜í¬ì¸íŠ¸": ""}
    
    try:
        import requests
        import json as json_module
        
        prompt = f"""ë‹¤ìŒ ë¸”ë¡œê·¸ ê¸€ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

ì œëª©: {title}
ë³¸ë¬¸: {content[:1500]}

ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "ìš”ì•½": "í•µì‹¬ ë‚´ìš© 3ì¤„ ìš”ì•½",
  "ì£¼ìš”ë‚´ìš©": "ê³ ê°ì´ ì–¸ê¸‰í•œ ì œí’ˆ íŠ¹ì§•",
  "ê²½ìŸì‚¬ì–¸ê¸‰": "ì–¸ê¸‰ëœ ê²½ìŸ ë¸Œëœë“œëª… (ì—†ìœ¼ë©´ ë¹ˆì¹¸)",
  "ê°ì„±": "ê¸ì • ë˜ëŠ” ì¤‘ë¦½ ë˜ëŠ” ë¶€ì •",
  "ì•¡ì…˜í¬ì¸íŠ¸": "ë³´ì–‘ëŒ€ì²© ê°œì„ ì‚¬í•­"
}}"""

        if AI_PROVIDER == "gemini":
            # Use gemini-2.0-flash (verified via ListModels API)
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"


            data = {
                "contents": [{"parts": [{"text": prompt}]}],
                "generationConfig": {"temperature": 0.3, "maxOutputTokens": 500}
            }
            response = requests.post(url, json=data, timeout=15)

            
            if response.status_code == 200:
                result = response.json()
                ai_response = result['candidates'][0]['content']['parts'][0]['text'].strip()
            else:
                print(f"      âš ï¸ Gemini ì‹¤íŒ¨ ({response.status_code})")
                return {"ìš”ì•½": "", "ì£¼ìš”ë‚´ìš©": "", "ê²½ìŸì‚¬ì–¸ê¸‰": "", "ê°ì„±": "", "ì•¡ì…˜í¬ì¸íŠ¸": ""}
        
        else:
            headers = {"Content-Type": "application/json", "Authorization": f"Bearer {OPENAI_API_KEY}"}
            data = {
                "model": "gpt-4o-mini",
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3,
                "max_tokens": 500
            }
            response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=data, timeout=15)
            
            if response.status_code == 200:
                result = response.json()
                ai_response = result['choices'][0]['message']['content'].strip()
            else:
                print(f"      âš ï¸ OpenAI ì‹¤íŒ¨ ({response.status_code})")
                return {"ìš”ì•½": "", "ì£¼ìš”ë‚´ìš©": "", "ê²½ìŸì‚¬ì–¸ê¸‰": "", "ê°ì„±": "", "ì•¡ì…˜í¬ì¸íŠ¸": ""}
        
        # JSON íŒŒì‹±
        try:
            if "```" in ai_response:
                ai_response = ai_response.split("```")[1]
                if ai_response.startswith("json"):
                    ai_response = ai_response[4:]
            
            analysis = json_module.loads(ai_response)
            return analysis
        except:
            return {"ìš”ì•½": ai_response[:100], "ì£¼ìš”ë‚´ìš©": "", "ê²½ìŸì‚¬ì–¸ê¸‰": "", "ê°ì„±": "", "ì•¡ì…˜í¬ì¸íŠ¸": ""}
            
    except Exception as e:
        print(f"      âš ï¸ AI ì˜¤ë¥˜: {str(e)[:50]}")
        return {"ìš”ì•½": "", "ì£¼ìš”ë‚´ìš©": "", "ê²½ìŸì‚¬ì–¸ê¸‰": "", "ê°ì„±": "", "ì•¡ì…˜í¬ì¸íŠ¸": ""}


def send_telegram_message(message):
    """í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ë°œì†¡"""
    try:
        import requests
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        data = {"chat_id": TELEGRAM_CHAT_ID, "text": message, "parse_mode": "HTML"}
        response = requests.post(url, data=data, timeout=10)
        
        if response.status_code == 200:
            print("âœ… í…”ë ˆê·¸ë¨ ë°œì†¡ ì„±ê³µ")
        else:
            print(f"âŒ í…”ë ˆê·¸ë¨ ë°œì†¡ ì‹¤íŒ¨: {response.status_code}")
    except Exception as e:
        print(f"âŒ í…”ë ˆê·¸ë¨ ë°œì†¡ ì˜¤ë¥˜: {e}")

def format_date(date_str):
    """ë‚ ì§œ í˜•ì‹ ë³€í™˜"""
    try:
        return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
    except:
        return date_str

def init_google_sheet():
    """êµ¬ê¸€ ì‹œíŠ¸ ì´ˆê¸°í™”"""
    try:
        if os.environ.get("GITHUB_ACTIONS"):
            print("â„¹ï¸ GitHub Env: Creating service_account.json from secret")
            json_content = os.environ.get("GOOGLE_SERVICE_ACCOUNT_JSON", "")
            if json_content:
                with open("service_account.json", "w") as f:
                    f.write(json_content)

        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds = ServiceAccountCredentials.from_json_keyfile_name(SERVICE_ACCOUNT_FILE, scope)
        client = gspread.authorize(creds)
        sheet = client.open_by_url(GOOGLE_SHEET_URL).sheet1
        
        if not sheet.row_values(1):
            sheet.append_row(["ìˆ˜ì§‘ì¼ì‹œ", "í‚¤ì›Œë“œ", "ì œëª©", "ë‚ ì§œ", "ë§í¬", "ìƒíƒœ", "ìš”ì•½", "ì£¼ìš”ë‚´ìš©", "ê²½ìŸì‚¬ì–¸ê¸‰", "ê°ì„±", "ì•¡ì…˜í¬ì¸íŠ¸"])
            print("âœ… ì‹œíŠ¸ í—¤ë” ì¶”ê°€ (Phase 2 í¬í•¨)")
            
        return sheet
    except Exception as e:
        print(f"âŒ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

def search_naver_blog(query):
    """ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰"""
    encText = urllib.parse.quote(query)
    url = f"https://openapi.naver.com/v1/search/blog?query={encText}&display={DISPLAY_COUNT}&sort={SORT_MODE}"
    
    request = urllib.request.Request(url)
    request.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
    request.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
    
    try:
        response = urllib.request.urlopen(request)
        if response.getcode() == 200:
            return json.loads(response.read().decode('utf-8'))
    except Exception as e:
        print(f"   âŒ API ì˜¤ë¥˜: {e}")
    return None

def main():
    print("ğŸš€ Viral Scout: Naver & Google Sheet Scanning Started...")
    
    # API í‚¤ ì²´í¬
    if ENABLE_AI_ANALYSIS:
        if AI_PROVIDER == "gemini":
            print(f"âœ… AI Provider: Gemini" + (" (API í‚¤ í™•ì¸ë¨)" if GEMINI_API_KEY else " âš ï¸ API í‚¤ ì—†ìŒ"))
        elif AI_PROVIDER == "openai":
            print(f"âœ… AI Provider: OpenAI" + (" (API í‚¤ í™•ì¸ë¨)" if OPENAI_API_KEY else " âš ï¸ API í‚¤ ì—†ìŒ"))
    
    sheet = init_google_sheet()
    if not sheet:
        print("ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨")
        return

    today_str = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    all_rows = []
    briefing_lines = []

    for keyword in SEARCH_KEYWORDS:
        print(f"\nğŸ” ê²€ìƒ‰ì–´: '{keyword}'")
        result = search_naver_blog(keyword)
        
        keyword_count = 0
        if result and 'items' in result:
            items = result['items']
            if not items:
                print("   (ê²°ê³¼ ì—†ìŒ)")
                continue

            for item in items:
                title = item['title'].replace('<b>', '').replace('</b>', '').replace('&quot;', '"')
                link = item['link']
                postdate = format_date(item['postdate'])
                description = item.get('description', '').replace('<b>', '').replace('</b>', '').replace('&quot;', '"')
                
                if is_blacklisted(title):
                    print(f"   ğŸš« ì œì™¸(ë¸”ë™ë¦¬ìŠ¤íŠ¸): {title[:40]}")
                    continue
                
                if not has_required_keyword(title):
                    print(f"   ğŸš« ì œì™¸(í•„ìˆ˜í‚¤ì›Œë“œ): {title[:40]}")
                    continue
                
                if not check_relevance_with_ai(title, description):
                    print(f"   ğŸš« ì œì™¸(AIíŒë‹¨): {title[:40]}")
                    continue
                
                print(f"   ğŸ“– í¬ë¡¤ë§: {title[:40]}...")
                content = scrape_blog_content(link)
                
                print(f"   ğŸ§  AI ë¶„ì„...")
                analysis = analyze_content_with_ai(title, content)
                
                row_data = [
                    today_str, keyword, title, postdate, link, "ì‹ ê·œ",
                    analysis.get("ìš”ì•½", ""),
                    analysis.get("ì£¼ìš”ë‚´ìš©", ""),
                    analysis.get("ê²½ìŸì‚¬ì–¸ê¸‰", ""),
                    analysis.get("ê°ì„±", ""),
                    analysis.get("ì•¡ì…˜í¬ì¸íŠ¸", "")
                ]
                
                all_rows.append(row_data)
                print(f"   âœ… ì¤€ë¹„: {title[:40]}")
                if analysis.get("ìš”ì•½"):
                    print(f"      ğŸ’¡ {analysis['ìš”ì•½'][:50]}...")
                
                keyword_count += 1
                if keyword_count <= 2:
                    briefing_lines.append(f"- [{keyword}] {title}")
                
                time.sleep(0.5)

        else:
            print("   (API ì‹¤íŒ¨)")
        
        time.sleep(1)

    # ë°°ì¹˜ ì €ì¥
    if all_rows:
        print(f"\nğŸ’¾ {len(all_rows)}ê±´ ì¼ê´„ ì €ì¥ ì¤‘...")
        try:
            sheet.append_rows(all_rows, value_input_option='RAW')
            print(f"âœ… {len(all_rows)}ê±´ ì €ì¥ ì™„ë£Œ!")
        except Exception as e:
            print(f"âŒ ë°°ì¹˜ ì‹¤íŒ¨: {e}")
            print("âš ï¸ ê°œë³„ ì €ì¥ ì¬ì‹œë„...")
            success = 0
            for row in all_rows:
                try:
                    sheet.append_row(row)
                    success += 1
                    time.sleep(2)
                except:
                    pass
            print(f"âœ… ê°œë³„ ì €ì¥: {success}/{len(all_rows)}ê±´")
    
    new_count = len(all_rows)
    print(f"\nğŸ‰ ì´ {new_count}ê±´ ì €ì¥ ì™„ë£Œ!")
    
    if new_count > 0:
        msg = f"ğŸŒ [Viral Scout ëª¨ë‹ ë¸Œë¦¬í•‘]\n\nì´ {new_count}ê±´ ìˆ˜ì§‘!\n({today_str})\n\n"
        if briefing_lines:
            msg += "ğŸ“‹ ìˆ˜ì§‘ ëª©ë¡:\n" + "\n".join(briefing_lines[:10]) + "\n..."
        msg += f"\n\nğŸ‘‰ {GOOGLE_SHEET_URL}"
        send_telegram_message(msg)
    else:
        print("ì‹ ê·œ ë°ì´í„° ì—†ìŒ")

if __name__ == "__main__":
    main()
